{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN classifier for the EMNIST dataset with data fetching and training running concurrently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shahidikram0701/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)\n",
    "\n",
    "    # Don't use tf.image.decode_image, or the output shape will be undefined\n",
    "    image = tf.image.decode_jpeg(image_string, channels=1)\n",
    "\n",
    "    # This will convert to float values in [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    #image = tf.image.resize_images(image, [64, 64])\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    mapping = pd.read_csv(\"train-labels.csv\", header = None)\n",
    "    \n",
    "    filenames = list(mapping.iloc[:,0])\n",
    "    labels = list(mapping.iloc[:,1])\n",
    "    \n",
    "    parse_fn = lambda f, l: _parse_function(f, l)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.shuffle(len(filenames))\n",
    "    dataset = dataset.map(parse_fn, num_parallel_calls=4)\n",
    "    #dataset = dataset.map(train_preprocess, num_parallel_calls=4)\n",
    "    dataset = dataset.repeat(5)\n",
    "    dataset = dataset.batch(64)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    \n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    images, labels = iterator.get_next()\n",
    "    #iterator = dataset.make_initializable_iterator()\n",
    "    #images, labels = iterator.get_next()\n",
    "    #iterator_init_op = iterator.initializer\n",
    "    \n",
    "    #inputs = {'images': images, 'labels': labels, 'iterator_init_op': iterator_init_op}\n",
    "    return {\"images\": images}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'images': array([[[[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        ..., \n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.01568628],\n",
      "         [ 0.02352941],\n",
      "         [ 0.00392157]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        ..., \n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        ..., \n",
      "        [[ 0.00392157],\n",
      "         [ 0.00784314],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.07450981],\n",
      "         [ 0.01960784],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.00784314],\n",
      "         [ 0.02352941],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]]],\n",
      "\n",
      "\n",
      "       ..., \n",
      "       [[[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.00392157],\n",
      "         [ 0.00392157],\n",
      "         [ 0.00392157]],\n",
      "\n",
      "        ..., \n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.        ],\n",
      "         [ 0.01568628],\n",
      "         [ 0.03137255],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.00392157]],\n",
      "\n",
      "        [[ 0.01568628],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.00392157],\n",
      "         [ 0.01960784]],\n",
      "\n",
      "        [[ 0.01960784],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        ..., \n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        ..., \n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.00784314],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]],\n",
      "\n",
      "        [[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         ..., \n",
      "         [ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]]]], dtype=float32)}, array([ 1, 24, 41, 34, 25,  4,  9,  3, 28,  2,  5, 28,  0, 25, 30,  7, 30,\n",
      "       40, 51, 36,  9, 23,  2, 31,  0, 21, 15, 55, 18, 27,  9, 24, 24,  7,\n",
      "       50,  6, 24,  7,  9,  5, 17, 40,  5, 43, 12,  8,  4, 14, 15, 15, 59,\n",
      "        9, 53,  5,  1, 54, 47,  4,  5,  5, 30,  8,  8, 11], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "# Test the input function\n",
    "\n",
    "next_batch = input_fn() \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    first_batch = sess.run(next_batch)\n",
    "    print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_x = tf.feature_column.numeric_column(\"images\", shape=784)\n",
    "feature_columns = [feature_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_hidden_units = [512, 256, 128]\n",
    "num_classes = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './checkpoints/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3bbb106ac8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                   hidden_units=num_hidden_units,\n",
    "                                   activation_fn=tf.nn.relu,\n",
    "                                   n_classes=num_classes,\n",
    "                                   model_dir=\"./checkpoints/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/model.ckpt-4188\n",
      "INFO:tensorflow:Saving checkpoints for 4189 into ./checkpoints/model.ckpt.\n",
      "INFO:tensorflow:loss = 35.8898, step = 4189\n",
      "INFO:tensorflow:global_step/sec: 0.961115\n",
      "INFO:tensorflow:loss = 27.3342, step = 4289 (104.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.93771\n",
      "INFO:tensorflow:loss = 32.4575, step = 4389 (51.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.71461\n",
      "INFO:tensorflow:loss = 32.3618, step = 4489 (26.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.21371\n",
      "INFO:tensorflow:loss = 48.6553, step = 4589 (10.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0651\n",
      "INFO:tensorflow:loss = 26.119, step = 4689 (6.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2814\n",
      "INFO:tensorflow:loss = 32.0038, step = 4789 (3.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4262\n",
      "INFO:tensorflow:loss = 30.0325, step = 4889 (3.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.3014\n",
      "INFO:tensorflow:loss = 33.935, step = 4989 (3.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4056\n",
      "INFO:tensorflow:loss = 26.5999, step = 5089 (3.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.2987\n",
      "INFO:tensorflow:loss = 43.7629, step = 5189 (3.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.946\n",
      "INFO:tensorflow:loss = 28.3134, step = 5289 (3.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.003\n",
      "INFO:tensorflow:loss = 58.4875, step = 5389 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.173\n",
      "INFO:tensorflow:loss = 32.1988, step = 5489 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.279\n",
      "INFO:tensorflow:loss = 30.8232, step = 5589 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.729\n",
      "INFO:tensorflow:loss = 47.3197, step = 5689 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.894\n",
      "INFO:tensorflow:loss = 31.4376, step = 5789 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.947\n",
      "INFO:tensorflow:loss = 34.1794, step = 5889 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.343\n",
      "INFO:tensorflow:loss = 35.8361, step = 5989 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.628\n",
      "INFO:tensorflow:loss = 27.1598, step = 6089 (0.551 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6188 into ./checkpoints/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 38.2137.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f3bbb1060b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_input_fn():\n",
    "    mapping = pd.read_csv(\"test-labels.csv\", header = None)\n",
    "    filenames = list(mapping.iloc[:,0])\n",
    "    labels = list(mapping.iloc[:,1])\n",
    "    \n",
    "    parse_fn = lambda f, l: _parse_function(f, l)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    #dataset = dataset.shuffle(len(filenames))\n",
    "    dataset = dataset.map(parse_fn, num_parallel_calls=4)\n",
    "    #dataset = dataset.map(train_preprocess, num_parallel_calls=4)\n",
    "    dataset = dataset.repeat(1)\n",
    "    dataset = dataset.batch(64)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    \n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    images, labels = iterator.get_next()\n",
    "    #iterator = dataset.make_initializable_iterator()\n",
    "    #images, labels = iterator.get_next()\n",
    "    #iterator_init_op = iterator.initializer\n",
    "    \n",
    "    #inputs = {'images': images, 'labels': labels, 'iterator_init_op': iterator_init_op}\n",
    "    return {\"images\": images}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-08-21-19:54:44\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/model.ckpt-6188\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-21-19:54:51\n",
      "INFO:tensorflow:Saving dict for global step 6188: accuracy = 0.798867, average_loss = 0.617792, global_step = 6188, loss = 39.4335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.79886669,\n",
       " 'average_loss': 0.61779195,\n",
       " 'global_step': 6188,\n",
       " 'loss': 39.433529}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/model.ckpt-6188\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(input_fn=test_input_fn)\n",
    "preds = []\n",
    "for prediction in predictions:\n",
    "    preds.append(prediction[\"class_ids\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test-labels.csv - contains the mappings of the filenames to thier labels\n",
    "mapping = pd.read_csv(\"test-labels.csv\", header = None)\n",
    "\n",
    "# actual labels\n",
    "actual = list(mapping.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act = tf.placeholder(tf.int64, shape = [15000])\n",
    "pred = tf.placeholder(tf.int64, shape = [15000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc, acc_op = tf.metrics.accuracy(labels=act, predictions=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.79886669]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run([acc, acc_op], feed_dict={act: actual, pred: preds}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision, precision_op = tf.metrics.precision(labels=act, predictions=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.98669392]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run([precision, precision_op], feed_dict={act: actual, pred: preds}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall, recall_op = tf.metrics.recall(labels=act, predictions=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.98178631]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run([recall, recall_op], feed_dict={act: actual, pred: preds}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = tf.confusion_matrix(labels=act, predictions=pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[536   0   1 ...,   0   0   0]\n",
      " [  0 811   1 ...,   0   0   0]\n",
      " [  0   0 711 ...,   1   0   9]\n",
      " ..., \n",
      " [  0   0   0 ...,  28   0   0]\n",
      " [  0   0   0 ...,   0  11   0]\n",
      " [  0   0  19 ...,   0   0  31]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(conf, feed_dict={act: actual, pred: preds}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acts_k = tf.placeholder(tf.int64, shape = [None])\n",
    "preds_k = tf.placeholder(tf.int64, shape = [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_k, recall_op_k = tf.metrics.recall(labels=acts_k, predictions=preds_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    :  [0.0, 0.0]\n",
      "1    :  [0.0, 1.0]\n",
      "2    :  [1.0, 1.0]\n",
      "3    :  [1.0, 1.0]\n",
      "4    :  [1.0, 1.0]\n",
      "5    :  [1.0, 1.0]\n",
      "6    :  [1.0, 1.0]\n",
      "7    :  [1.0, 1.0]\n",
      "8    :  [1.0, 0.99967009]\n",
      "9    :  [0.99967009, 0.99970603]\n",
      "10    :  [0.99970603, 0.99971181]\n",
      "11    :  [0.99971181, 0.99957317]\n",
      "12    :  [0.99957317, 0.9993099]\n",
      "13    :  [0.9993099, 0.99781722]\n",
      "14    :  [0.99781722, 0.99785149]\n",
      "15    :  [0.99785149, 0.99791175]\n",
      "16    :  [0.99791175, 0.99779594]\n",
      "17    :  [0.99779594, 0.99781209]\n",
      "18    :  [0.99781209, 0.99787927]\n",
      "19    :  [0.99787927, 0.99790329]\n",
      "20    :  [0.99790329, 0.99791694]\n",
      "21    :  [0.99791694, 0.99794042]\n",
      "22    :  [0.99794042, 0.99798435]\n",
      "23    :  [0.99798435, 0.99802488]\n",
      "24    :  [0.99802488, 0.97643322]\n",
      "25    :  [0.97643322, 0.97690159]\n",
      "26    :  [0.97690159, 0.97651327]\n",
      "27    :  [0.97651327, 0.97681284]\n",
      "28    :  [0.97681284, 0.97780246]\n",
      "29    :  [0.97780246, 0.97823936]\n",
      "30    :  [0.97823936, 0.97857559]\n",
      "31    :  [0.97857559, 0.97869086]\n",
      "32    :  [0.97869086, 0.97889256]\n",
      "33    :  [0.97889256, 0.97902364]\n",
      "34    :  [0.97902364, 0.97925198]\n",
      "35    :  [0.97925198, 0.97937286]\n",
      "36    :  [0.97937286, 0.97954357]\n",
      "37    :  [0.97954357, 0.97975343]\n",
      "38    :  [0.97975343, 0.97975093]\n",
      "39    :  [0.97975093, 0.98014581]\n",
      "40    :  [0.98014581, 0.9810068]\n",
      "41    :  [0.9810068, 0.98109734]\n",
      "42    :  [0.98109734, 0.98114306]\n",
      "43    :  [0.98114306, 0.98144364]\n",
      "44    :  [0.98144364, 0.9815312]\n",
      "45    :  [0.9815312, 0.98159111]\n",
      "46    :  [0.98159111, 0.98167288]\n",
      "47    :  [0.98167288, 0.98215967]\n",
      "48    :  [0.98215967, 0.98223507]\n",
      "49    :  [0.98223507, 0.98255455]\n",
      "50    :  [0.98255455, 0.98018211]\n",
      "51    :  [0.98018211, 0.98019803]\n",
      "52    :  [0.98019803, 0.98030603]\n",
      "53    :  [0.98030603, 0.98072791]\n",
      "54    :  [0.98072791, 0.98080611]\n",
      "55    :  [0.98080611, 0.98131514]\n",
      "56    :  [0.98131514, 0.98139268]\n",
      "57    :  [0.98139268, 0.98147094]\n",
      "58    :  [0.98147094, 0.98155242]\n",
      "59    :  [0.98155242, 0.98162413]\n",
      "60    :  [0.98162413, 0.98170304]\n",
      "61    :  [0.98170304, 0.98178631]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for k in range(62):\n",
    "        temp = [(actual[i],preds[i]) for i in range(15000) if actual[i]==k]\n",
    "        temp2 = list(zip(*temp))\n",
    "        actual_k=list(temp2[0])\n",
    "        pred_k=list(temp2[1])\n",
    "        print(k, \"   : \", end = \" \")\n",
    "        print(sess.run([recall_k, recall_op_k], feed_dict={acts_k: actual_k, preds_k: pred_k}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_k, precision_op_k = tf.metrics.precision(labels=acts_k, predictions=preds_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    :  [0.0, 0.0]\n",
      "1    :  [0.0, 0.81999999]\n",
      "2    :  [0.81999999, 0.89540672]\n",
      "3    :  [0.89540672, 0.92736357]\n",
      "4    :  [0.92736357, 0.94373327]\n",
      "5    :  [0.94373327, 0.95271456]\n",
      "6    :  [0.95271456, 0.95994914]\n",
      "7    :  [0.95994914, 0.96584129]\n",
      "8    :  [0.96584129, 0.96975517]\n",
      "9    :  [0.96975517, 0.97296524]\n",
      "10    :  [0.97296524, 0.97348112]\n",
      "11    :  [0.97348112, 0.97380459]\n",
      "12    :  [0.97380459, 0.97455919]\n",
      "13    :  [0.97455919, 0.97481006]\n",
      "14    :  [0.97481006, 0.97519684]\n",
      "15    :  [0.97519684, 0.97587746]\n",
      "16    :  [0.97587746, 0.97603041]\n",
      "17    :  [0.97603041, 0.97620249]\n",
      "18    :  [0.97620249, 0.97691745]\n",
      "19    :  [0.97691745, 0.97717392]\n",
      "20    :  [0.97717392, 0.97731912]\n",
      "21    :  [0.97731912, 0.9775694]\n",
      "22    :  [0.9775694, 0.97803855]\n",
      "23    :  [0.97803855, 0.97847134]\n",
      "24    :  [0.97847134, 0.97922391]\n",
      "25    :  [0.97922391, 0.97963798]\n",
      "26    :  [0.97963798, 0.97975576]\n",
      "27    :  [0.97975576, 0.9800148]\n",
      "28    :  [0.9800148, 0.98087043]\n",
      "29    :  [0.98087043, 0.98124814]\n",
      "30    :  [0.98124814, 0.98170203]\n",
      "31    :  [0.98170203, 0.9818809]\n",
      "32    :  [0.9818809, 0.98205298]\n",
      "33    :  [0.98205298, 0.98216474]\n",
      "34    :  [0.98216474, 0.98235953]\n",
      "35    :  [0.98235953, 0.98246264]\n",
      "36    :  [0.98246264, 0.98276019]\n",
      "37    :  [0.98276019, 0.98293763]\n",
      "38    :  [0.98293763, 0.9830097]\n",
      "39    :  [0.9830097, 0.98334217]\n",
      "40    :  [0.98334217, 0.98406678]\n",
      "41    :  [0.98406678, 0.98414296]\n",
      "42    :  [0.98414296, 0.98425001]\n",
      "43    :  [0.98425001, 0.98450184]\n",
      "44    :  [0.98450184, 0.98457521]\n",
      "45    :  [0.98457521, 0.9846254]\n",
      "46    :  [0.9846254, 0.98469388]\n",
      "47    :  [0.98469388, 0.9851017]\n",
      "48    :  [0.9851017, 0.98516482]\n",
      "49    :  [0.98516482, 0.98543239]\n",
      "50    :  [0.98543239, 0.9854604]\n",
      "51    :  [0.9854604, 0.98552722]\n",
      "52    :  [0.98552722, 0.98560655]\n",
      "53    :  [0.98560655, 0.98591655]\n",
      "54    :  [0.98591655, 0.98597401]\n",
      "55    :  [0.98597401, 0.98634785]\n",
      "56    :  [0.98634785, 0.98640484]\n",
      "57    :  [0.98640484, 0.9864623]\n",
      "58    :  [0.9864623, 0.98652214]\n",
      "59    :  [0.98652214, 0.98657477]\n",
      "60    :  [0.98657477, 0.9866327]\n",
      "61    :  [0.9866327, 0.98669392]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for k in range(62):\n",
    "        temp = [(actual[i],preds[i]) for i in range(15000) if actual[i]==k]\n",
    "        temp2 = list(zip(*temp))\n",
    "        actual_k=list(temp2[0])\n",
    "        pred_k=list(temp2[1])\n",
    "        print(k, \"   : \", end = \" \")\n",
    "        print(sess.run([precision_k, precision_op_k], feed_dict={acts_k: actual_k, preds_k: pred_k}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
